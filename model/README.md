# Modelo de Machine Learning - Terapp.IA

Este projeto contÃ©m o notebook Jupyter usado para treinar o modelo de Machine Learning que detecta risco de depressÃ£o em estudantes.

## ğŸ““ Sobre o Notebook (`terappia_model.ipynb`)

O notebook documenta todo o processo de criaÃ§Ã£o do modelo de prediÃ§Ã£o, desde a obtenÃ§Ã£o dos dados atÃ© a exportaÃ§Ã£o do modelo final para ser usado na API.

---

## ğŸ¯ Objetivo do Projeto

Criar um modelo de Machine Learning capaz de **identificar estudantes em risco de depressÃ£o** com base em fatores psicossociais e acadÃªmicos, para permitir intervenÃ§Ãµes preventivas e direcionadas.

---

## ğŸ“Š Dataset Utilizado

**Fonte:** [Student Depression Dataset - Kaggle](https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset)

O dataset original contÃ©m informaÃ§Ãµes sobre estudantes incluindo:
- Dados demogrÃ¡ficos (idade, gÃªnero, cidade)
- InformaÃ§Ãµes acadÃªmicas (curso, CR, satisfaÃ§Ã£o com estudos)
- Fatores de risco (pressÃ£o acadÃªmica, estresse financeiro, pensamentos suicidas)
- HÃ¡bitos de vida (sono, alimentaÃ§Ã£o, horas de estudo)
- HistÃ³rico familiar de doenÃ§as mentais

---

## ğŸ”§ Processamento dos Dados

### **Dados Removidos**
Algumas colunas foram removidas por nÃ£o serem relevantes para o modelo:
- **ID**: Identificador Ãºnico, nÃ£o tem valor preditivo
- **Cidade**: LocalizaÃ§Ã£o geogrÃ¡fica nÃ£o mostrou relevÃ¢ncia
- **Curso/Degree**: Tipo de graduaÃ§Ã£o nÃ£o impactou significativamente
- **ProfissÃ£o**: Focado apenas em estudantes
- **Job Satisfaction**: Relacionado a trabalho, nÃ£o a estudos
- **Work Pressure**: PressÃ£o de trabalho (mantemos apenas pressÃ£o acadÃªmica)

### **Limpeza de Dados**
- RemoÃ§Ã£o de valores invÃ¡lidos (ex: "?" em estresse financeiro)
- RemoÃ§Ã£o de linhas com dados faltantes (NaN)

### **TraduÃ§Ã£o para PortuguÃªs**
Para facilitar o uso na aplicaÃ§Ã£o brasileira, os dados foram traduzidos:
- **GÃªnero**: Male â†’ Masculino, Female â†’ Feminino
- **DuraÃ§Ã£o do Sono**: Less than 5 hours â†’ Menos de 5 horas, etc.
- **HÃ¡bitos Alimentares**: Healthy â†’ Muito saudÃ¡veis, Moderate â†’ Moderadamente saudÃ¡veis
- **Respostas Sim/NÃ£o**: Yes â†’ Sim, No â†’ NÃ£o

---

## ğŸ§  Modelo Utilizado: SVM (Support Vector Machine)

### **O que Ã© SVM?**
SVM (MÃ¡quina de Vetores de Suporte) Ã© um algoritmo de Machine Learning usado para classificaÃ§Ã£o. Ele funciona encontrando o melhor "limite de decisÃ£o" entre duas classes de dados.

**Imagine assim:**
- VocÃª tem pontos vermelhos (estudantes com depressÃ£o) e pontos azuis (estudantes sem depressÃ£o) espalhados em um grÃ¡fico
- O SVM desenha uma linha (ou superfÃ­cie) que melhor separa esses dois grupos
- Novos estudantes sÃ£o classificados baseado em qual lado da linha eles caem

### **Por que SVM com Kernel RBF?**
Usamos SVM com **kernel RBF (Radial Basis Function)** porque:

âœ… **NÃ£o Linear**: A relaÃ§Ã£o entre os fatores e a depressÃ£o nÃ£o Ã© uma linha reta simples. O kernel RBF permite capturar padrÃµes complexos e curvas nos dados.

âœ… **RelaÃ§Ãµes Complexas**: Consegue identificar interaÃ§Ãµes entre mÃºltiplos fatores (ex: pressÃ£o acadÃªmica + falta de sono = risco maior)

âœ… **Boa Performance**: Mostrou alta acurÃ¡cia e recall nos testes

âœ… **Robusto**: Funciona bem mesmo com dados que tÃªm distribuiÃ§Ãµes complexas

### **ConfiguraÃ§Ãµes do Modelo**
```python
SVC(kernel='rbf', probability=True, random_state=42)
```
- **kernel='rbf'**: Usa funÃ§Ã£o de base radial (nÃ£o linear)
- **probability=True**: Permite calcular probabilidades das prediÃ§Ãµes
- **random_state=42**: Garante reprodutibilidade dos resultados

---

## ğŸ”„ Pipeline de Processamento

O modelo usa um **Pipeline** que combina prÃ©-processamento e classificaÃ§Ã£o:

### **1. PrÃ©-processamento AutomÃ¡tico**

**Para Dados NumÃ©ricos** (idade, CR, horas de estudo, etc.):
- **StandardScaler**: Normaliza os valores para terem a mesma escala
- Por quÃª? Evita que features com valores grandes dominem o modelo

**Para Dados CategÃ³ricos** (gÃªnero, sono, alimentaÃ§Ã£o, etc.):
- **OneHotEncoder**: Transforma categorias em nÃºmeros binÃ¡rios
- Exemplo: "Masculino" vira [1, 0], "Feminino" vira [0, 1]
- Por quÃª? Modelos de ML sÃ³ entendem nÃºmeros

### **2. ClassificaÃ§Ã£o**
ApÃ³s o prÃ©-processamento, o SVM faz a classificaÃ§Ã£o:
- Entrada: 11 caracterÃ­sticas do estudante
- SaÃ­da: Depressivo (1) ou NÃ£o Depressivo (0)

---

## ğŸ“ˆ MÃ©tricas de Performance

O modelo foi avaliado usando:

### **AcurÃ¡cia**
Percentual de prediÃ§Ãµes corretas no total.
- Mede o quÃ£o frequente o modelo acerta

### **Recall (Sensibilidade)**
Percentual de casos de depressÃ£o que o modelo conseguiu identificar.
- **MÃ©trica mais importante neste projeto!**
- Por quÃª? Ã‰ melhor ter um "falso alarme" do que perder um caso real de depressÃ£o

---

## ğŸ¯ ImportÃ¢ncia das Features (Fatores)

AtravÃ©s da anÃ¡lise de **Permutation Feature Importance**, descobrimos o quanto cada fator contribui para a prediÃ§Ã£o:

### **Como funciona?**
Embaralhamos os valores de uma feature e medimos quanto a performance do modelo piora:
- Se piorar muito = feature muito importante
- Se piorar pouco = feature pouco importante

### **Ranking de ImportÃ¢ncia**

**ğŸ”´ ALTO IMPACTO (>15%)**
1. **Pensamentos Suicidas** (~48.5%) ğŸš¨ CRÃTICO
   - De longe o fator mais importante
   - Indicador direto de risco grave

2. **PressÃ£o AcadÃªmica** (~26.1%) âš ï¸ MUITO ALTO
   - Segundo fator mais relevante
   - Relacionado a estresse e sobrecarga

**ğŸŸ¡ MÃ‰DIO IMPACTO (5-15%)**
3. **Estresse Financeiro** (~11.4%)
   - PreocupaÃ§Ãµes econÃ´micas impactam saÃºde mental

4. **Idade** (~5.9%)
   - Diferentes faixas etÃ¡rias tÃªm vulnerabilidades distintas

**ğŸŸ¢ BAIXO IMPACTO (<5%)**
5. Horas de Estudo/Trabalho (~2.4%)
6. HÃ¡bitos Alimentares (~2.4%)
7. SatisfaÃ§Ã£o com Estudos (~2.3%)
8. DuraÃ§Ã£o do Sono (~0.6%)
9. GÃªnero (~0.4%)
10. HistÃ³rico Familiar (~0.1%)
11. CR/CGPA (~-0.1%)

### **Insights Importantes**

âœ… **Foco em Fatores de Alto Impacto**: Pensamentos suicidas e pressÃ£o acadÃªmica representam mais de 70% da importÃ¢ncia total.

âœ… **Modelo NÃ£o Linear Ã© Essencial**: As interaÃ§Ãµes complexas entre fatores sÃ³ sÃ£o capturadas pelo kernel RBF.

âœ… **Recall Ã© Prioridade**: Melhor identificar mais casos (incluindo falsos positivos) do que perder casos reais.

âš ï¸ **LimitaÃ§Ã£o**: O modelo nÃ£o mostra a direÃ§Ã£o da influÃªncia (positiva ou negativa), apenas a importÃ¢ncia.

---

## ğŸ’¾ ExportaÃ§Ã£o do Modelo

ApÃ³s o treinamento, o modelo completo (pipeline com prÃ©-processamento + SVM) Ã© salvo:

```python
joblib.dump(svm_pipeline, 'student-depression-svm.joblib')
```

Este arquivo `.joblib` contÃ©m:
- O modelo SVM treinado
- O prÃ©-processador (StandardScaler + OneHotEncoder)
- Todos os parÃ¢metros e configuraÃ§Ãµes

**Onde Ã© usado?**
O arquivo Ã© carregado pela API (`student-depression-api`) para fazer prediÃ§Ãµes em tempo real quando usuÃ¡rios respondem o questionÃ¡rio.

---

## ğŸ”¬ Tecnologias Utilizadas

| Biblioteca | VersÃ£o | Uso |
|------------|--------|-----|
| **scikit-learn** | - | Modelo SVM e prÃ©-processamento |
| **pandas** | - | ManipulaÃ§Ã£o de dados |
| **numpy** | - | CÃ¡lculos numÃ©ricos |
| **seaborn** | - | VisualizaÃ§Ã£o de dados |
| **matplotlib** | - | GrÃ¡ficos |
| **joblib** | - | Salvar/carregar modelo |
| **kagglehub** | - | Download do dataset |

---

## ğŸ“š Estrutura do Notebook

1. **Setup**: InstalaÃ§Ã£o de dependÃªncias
2. **Download Dataset**: ObtÃ©m dados do Kaggle
3. **VisualizaÃ§Ã£o**: GrÃ¡ficos exploratÃ³rios dos dados
4. **Processamento**: Limpeza e transformaÃ§Ã£o
5. **Treinamento**: CriaÃ§Ã£o do pipeline e treino do SVM
6. **AnÃ¡lise**: MÃ©tricas e importÃ¢ncia das features
7. **ExportaÃ§Ã£o**: Salvamento do modelo final

---

## ğŸš€ Como Usar Este Notebook

### **PrÃ©-requisitos**
- Python 3.8+
- Conta no Kaggle (para download do dataset)
- Jupyter Notebook ou Google Colab

### **Executar Localmente**

1. **Instalar dependÃªncias**
```bash
pip install kaggle kagglehub pandas scikit-learn seaborn matplotlib joblib
```

2. **Configurar credenciais do Kaggle**
- Baixe seu `kaggle.json` da sua conta
- Coloque em `~/.kaggle/kaggle.json`

3. **Executar o notebook**
```bash
jupyter notebook terappia_model.ipynb
```

### **Executar no Google Colab**
1. FaÃ§a upload do notebook para o Colab
2. Execute as cÃ©lulas sequencialmente
3. FaÃ§a upload do `kaggle.json` quando solicitado

---

## ğŸ“Š Resultados Esperados

ApÃ³s executar o notebook completo, vocÃª terÃ¡:

âœ… Modelo SVM treinado e validado
âœ… AnÃ¡lise detalhada da importÃ¢ncia de cada feature
âœ… MÃ©tricas de performance (acurÃ¡cia e recall)
âœ… Arquivo `.joblib` pronto para uso na API
âœ… VisualizaÃ§Ãµes dos dados e resultados

---

## ğŸ”„ IntegraÃ§Ã£o com o Sistema

```
Notebook (terappia_model.ipynb)
     â†“
[Treina modelo SVM]
     â†“
Exporta: student-depression-svm.joblib
     â†“
Copia para: student-depression-api/src/resources/
     â†“
API carrega modelo
     â†“
Frontend faz requisiÃ§Ãµes
     â†“
UsuÃ¡rios recebem prediÃ§Ãµes
```

---

## ğŸ“ ObservaÃ§Ãµes Importantes

âš ï¸ **NÃ£o Ã© DiagnÃ³stico MÃ©dico**: Este modelo Ã© uma ferramenta de triagem, nÃ£o substitui avaliaÃ§Ã£o profissional.

ğŸ”’ **Privacidade**: NÃ£o armazenamos dados dos usuÃ¡rios. As prediÃ§Ãµes sÃ£o feitas em tempo real e descartadas.

ğŸ¯ **Recall PrioritÃ¡rio**: O modelo Ã© configurado para ser mais sensÃ­vel (identificar mais casos), aceitando alguns falsos positivos para nÃ£o perder casos reais.

ğŸ”„ **Modelo EstÃ¡tico**: O modelo nÃ£o aprende com novos dados automaticamente. Necessita retreinamento periÃ³dico.

---

## ğŸ¤ Contribuindo

Para melhorar o modelo:
1. Experimente diferentes hiperparÃ¢metros do SVM
2. Teste outros algoritmos para comparaÃ§Ã£o
3. Adicione novas features relevantes
4. Aumente o dataset com mais dados
5. Implemente validaÃ§Ã£o cruzada

---

## ğŸ“š ReferÃªncias

- [Dataset Original - Kaggle](https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset)
- [DocumentaÃ§Ã£o scikit-learn SVM](https://scikit-learn.org/stable/modules/svm.html)
- [Permutation Feature Importance](https://scikit-learn.org/stable/modules/permutation_importance.html)
